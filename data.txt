  /**
     * Get chunk factor
     * @return int
     */
	public int getChunkFactor() {
		try {
			if (chunkFactor == 1) {
				String depJobID = getDependentJobId();
				if (depJobID != null && !depJobID.trim().isEmpty()) {
					chunkFactor = getChunkFactor(depJobID); // chunk factor
															// should be kept on
															// the job that will
															// be chunked and
															// not on the pilot
															// job
				} else {
					return 1;
				}
			}
		} catch (Exception e) {
			throw new FwException(FwConstants.LOGGING_CATEGORY_FRAMEWORK,
					ILog.ERROR, e);
		}
		return chunkFactor;
	}

    /**
     * Get chunk factor
     * @param ajobId The identifier for the job
     * @return int returns count of records
     */
	public int getChunkFactor(String ajobId) {
		int lchunkFactor = 1;// chunk factor is 1 means that number of instances
								// will correspond to 1 workload
		String refValue = null;
		try {
			ReferenceTableReader refTableRead = ReferenceTableReader
					.getInstance();
			refValue = refTableRead.readReferenceTable(
					BatchConstants.RT_BATCH_JOB_CONTROL, ajobId,
					BatchConstants.RF_CHUNKFACTOR);
		} catch (Exception e) {
			throw new FwException(FwConstants.LOGGING_CATEGORY_FRAMEWORK,
					ILog.ERROR, e);
		}
		if (refValue != null && !refValue.trim().isEmpty()) {
			lchunkFactor = Integer.valueOf(refValue);
		} 
		return lchunkFactor;
	}

    /**
     * Gets the batchControllers
     * @return ITIERSBatchController
     */
    public static ITIERSBatchController getBatchControllers() {
        return batchController;
    }

    /**
     * This method gets the Processor Job Id
     * @return String returns dependent Job id
     * @throws TIERSBatchException 
     */
    public String getDependentJobId() throws TIERSBatchException {

        if (dependentJobId == null) {
            try {
                ReferenceTableReader refTableRead = ReferenceTableReader.getInstance();
                dependentJobId = refTableRead.readReferenceTable(BatchConstants.RT_BATCH_JOB_CONTROL, getJobId(),BatchConstants.RF_DEPENDENT_JOB);
            } catch (Exception e) {
                throw new TIERSBatchException(
                        "Error in getting dependent job Id from reference table: "+e.getMessage(), e);
            }
        }

        if (dependentJobId.trim().length() == 0) {

            FwBatchContextCargo params = new FwBatchContextCargo();
            int contextCommitSize = 0;
            params.setJobId(getJobId());
            params.setKeyColumn(BatchConstants.RF_DEPENDENT_JOB);

            FwBatchContextCargo[] fwBatchContextCargo = null;

            FwBatchContextCollection contextCollection = new FwBatchContextCollection(
                    getConnection());
            contextCollection.setCargo(params);
            try {
                fwBatchContextCargo = (FwBatchContextCargo[]) contextCollection
                        .select("findByCommitKey");
            } catch (Exception e) {
                throw new TIERSBatchException(
                        "Error While getting the Records from FW_batch_context Table"
                                + e.getMessage(), e);
            }

            if (fwBatchContextCargo != null && fwBatchContextCargo.length > 0)

                dependentJobId = fwBatchContextCargo[0].getJobKeyValue();

        }

        return dependentJobId;
    }

    /**
     * This method decides whether it needs to be a single FTP for the files
     * @return boolean returns true or false
     * @throws TIERSBatchException 
     */
  private boolean isSingleFTP(){
        if (gsingleFTP == BatchConstants.NOTAPPLICABLE) {
        	String refValue = null;
            try {
                ReferenceTableReader refTableRead = ReferenceTableReader
                        .getInstance();
                refValue = refTableRead.readReferenceTable(
                        BatchConstants.RT_BATCH_JOB_CONTROL, getJobId(),
                        BatchConstants.RF_SINGLE_FTP);
            } catch (Exception e) {
            	throw new FwException(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, e);
            }
			if (refValue != null && !refValue.trim().isEmpty()) {
				gsingleFTP = refValue.toCharArray()[0];
			} else {
				return true;
			}
        }
        return (gsingleFTP == BatchConstants.YES);
    }

    /**
     * This method decides whether it needs to isLastParallelInstance
     * @return boolean returns true or false
     * @throws TIERSBatchException 
     */
    boolean isLastParallelInstance() throws TIERSBatchException {
        if (!glastInstance) {
            glastInstance = brcDAO.isLastParallelInstance(
                    getTIERSBatchControllerConnection(), getJobId(),
                    getAsOfDate(), getParallelRunNum());
        }
        return glastInstance;
    }

    /**
     * This method validates the MQ environment
     * @throws TIERSBatchException
     */
    private void validateMQManager() throws TIERSBatchException {
        try {
            FwMessageQueueValidator.validateBatchMQ();
        } catch (Exception e) {
            /*if the message is JMS exceptions, then skip it. If the batch job does not
             * need messaging, it can continue to run. If it needs, messaging, the job
             * will get authentication exception when it tries to send/receive messages, 
             * from FwMessageManager. If the exception is due to message authentication 
             * failure, throw TIERSBatchException and stop the job.
             */
            String message = e.getMessage();
            if (message.indexOf("Messaging environment authentication failed") > 0) {
                throw new TIERSBatchException(e.getMessage(), e);
            }
        }
    }
    
    /**
     * This method gets Max run num.
     * @param conn Batch Connection
     * @param ajobId The identifier for the job
     * @param asofDt Has the as of date of the job
     * @return long returns max. runNum
     * @throws TIERSBatchException
     */
    public long getMaxRunningNum(Connection conn, String jobId, String asOfDt)
            throws RecordNotExistsException, TIERSBatchException {

        long runNum = 0;
        runNum = brcDAO.getMaxRunningNum(conn, jobId, asOfDt);
        return runNum;

    }
    
    
    /**
     * This Method gets Max. RunNum from File Control 
     * @param conn Batch Connection
     * @param ajobId The identifier for the job
     * @param asofDt Has the as of date of the job
     * @return long returns max. runNum
     * @throws RecordNotExistsException 
     * @throws TIERSBatchException  
     */
    public long getMaxFileControlRunNum(Connection conn, String jobId, String asOfDt)
    throws RecordNotExistsException, TIERSBatchException {

        long runNum = 0;

    //    runNum = bfcDAO.getMaxRunNumOfAsOfDate(conn,jobId,"filename",asOfDt);

        //findByMaxRunNumOfAsOfDate

        return runNum;

    }
    
    // Added BY Gopi Gunda

    // Method add to insert a record into file control table used by RP and FM track 
    // Once PDF is created using JRC this table will be populated so that PDF will be sent to CPC only once 
    // by updating status cd after sending to CPC
    /**
     * This Method gets Max. RunNum from File Control 
     * @param reportId Id to be processed
     * @param runNum Has the run number of the particular run
     * @param fileId Id to be processed
     * @return boolean returns true or false 
     * @throws TIERSBatchException
     */
    public boolean insertIntoFileControl(String reportId, int runNum,
            long fileId) throws TIERSBatchException {

        boolean insertSuccessful = false;

        try {
            if (asOfDate == null) {
                asOfDate = bpcDAO.findAsOfDate(
                        getTIERSBatchControllerConnection(), jobId);
            }
        } catch (Exception ex) {
            throw new TIERSBatchException("Error in finding AsOfDate "
                    + ex.getMessage(), ex);
        }

        insertSuccessful = bfcDAO.insertIntoFileControlForRP(
                getTIERSBatchControllerConnection(), jobId, reportId, getAsOfDate(),
                runNum, createUpdateUserId, fileId);

        return insertSuccessful;

    }

    /**
     * This Method gets file
     * @param conn Batch Connection
     * @return long returns fileId
     * @throws TIERSBatchException
     */
    public long getFileId(Connection conn) throws TIERSBatchException{
    	

    	FwBatchFtpRunControlCargo[] params = { new FwBatchFtpRunControlCargo()};
    	FwBatchFtpRunControlCollection fwbftprCollection=null;
    	FwBatchFtpRunControlCargo[] retCargos = null;
    	try {
    		if (fwbftprCollection == null) {
    			fwbftprCollection = new FwBatchFtpRunControlCollection(conn);
    			fwbftprCollection.setEJBSupported(false);
    		}
    	
    		retCargos =
    			(FwBatchFtpRunControlCargo[]) fwbftprCollection.select(
    					"findByFileId",
    					params);

    				
    	}catch (Exception e) {
    		throw new TIERSBatchException(
    					"Error while getting FileID Information from FW_BATCH_FILE. " + e.getMessage(), e);		
    	}

    	
    	return retCargos[0].getFileId();
    	
    }
    
    /**
     * This Method inserts into ftp Run Control 
     * @param  fileId Id to be processed
     * @param  fileName name of the File to be processed
     * @param  CreateUserId userid to be processed
     * @return boolean returns fileId 
     * @throws TIERSBatchException
     * @throws ApplicationException
     * @throws FrameworkException  
     */
    public boolean insertIntoFtpRunControl( long fileId,String fileName, String CreateUserId) throws TIERSBatchException, ApplicationException, FrameworkException{
 		
 	boolean insertSuccessful = false;
 	bfcDAO.insertIntoFtpRunControl(getTIERSBatchControllerConnection(), fileName, CreateUserId, fileId);	
 	return insertSuccessful;
 	
 }
    
	/**
	 * This Method gets file
	 * 
	 * @param conn
	 *            Batch Connection
	 * @param jobId
	 *            The identifier for the job
	 * @param start
	 *            starttime for job
	 * @param end
	 *            endtime for job
	 * @return boolean returns true or false
	 * @throws ApplicationException
	 */
	public boolean ranSuccessfullyForGivenRange(Connection conn, String jobId,
			Timestamp start, Timestamp end) throws ApplicationException {

		boolean result = false;

		Object[] params = { jobId, start, end };

		FwBatchRunControlCollection batchRunControlCollection = new FwBatchRunControlCollection(
				conn);
		FwBatchRunControlCargo[] returnRunControlCargos;

		try {
			returnRunControlCargos = (FwBatchRunControlCargo[]) batchRunControlCollection
					.select("findBySuccessDateRange", params);

		} catch (Exception ex) {
			getLogger()
					.log(FwConstants.LOGGING_CATEGORY_FRAMEWORK,
							ILog.ERROR,
							"Error while reading from FW_BATCH_RUN_CONTROL with finder findBySuccessDateRange. Message: "
									+ ex.getMessage(), ex);
			throw new TIERSBatchException(
					"Error while reading from FW_BATCH_RUN_CONTROL with finder findBySuccessDateRange. Message: "
							+ ex.getMessage(), ex);
		}

		if (returnRunControlCargos != null && returnRunControlCargos.length > 0) {
			result = true;
		}

		return result;
	}
    

    /**
     * @return Returns the gsingleFTP.
     */
    public char getGsingleFTP() {
        return gsingleFTP;
    }
    /**
     * @param gsingleFTP The gsingleFTP to set.
     */
    public void setGsingleFTP(boolean flag) {
        if (flag == true){
        this.gsingleFTP = BatchConstants.YES;
    }else{
        this.gsingleFTP = BatchConstants.NO;
    }
  }

	/**
	 * This Method gets file Record Count
	 * 
	 * @param AbsFileName
	 *            absolute file name
	 * @return long returns record count of file
	 * @throws TIERSBatchException
	 */
	public long getFileRecordCount(String AbsFileName) throws TIERSBatchException {

		Process p = null;
		Runtime rt = null;
		int waitWC = -1;
		boolean wcSuccessful = false;
		StringBuffer sbf = new StringBuffer();
		String str1 = null;
		StringTokenizer stk = null;
		long recordCount = 0L;
		int count = 0;
		BufferedReader stdError = null;
		BufferedReader stdOut = null;
		
		try {
			
			while (count <= 5 && !wcSuccessful) {
				
				rt = Runtime.getRuntime();
				p = rt.exec("wc -l " + StringEscapeUtils.escapeSql(AbsFileName));
				waitWC = p.waitFor();
				
				if (waitWC != 0) {
				
					try {
						 stdError = new BufferedReader(new InputStreamReader(p.getErrorStream()));
						while ((stdError.readLine()) != null) {
							sbf.append(stdError.readLine());
							wcSuccessful = false;
						}
					} catch (IOException e) {
						throw new FwException(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, e);
					}finally{
						stdError.close();
					}
					
				} else {
					stdOut = new BufferedReader(new InputStreamReader(p.getInputStream()));
					while ((str1 = stdOut.readLine()) != null) {
						stk = new StringTokenizer(str1);
					}					
				}
				String str = new String();

				Long longObject = null;
				if (stk != null) {
					while (stk.hasMoreTokens()) {
						str = stk.nextToken();
						break;
					}
				}
				longObject = new Long(str);
				recordCount = longObject.longValue();

				if (waitWC == 0) {
					wcSuccessful = true;
				}
				count++;
				Thread.sleep(1000);
			}
		} catch (Exception ex) {
			getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR,
					"Error in getFileRecordCount. Message: " + ex.getMessage(),	ex);
			throw new TIERSBatchException("Error in getFileRecordCount. Message: " + ex.getMessage(), ex);
		} finally {
			try {
				if(stdOut != null)
					stdOut.close();
			} catch (IOException ioe) {
				throw new TIERSBatchException(ioe);
			}
		}
		return recordCount;
	}
   
    /**
     * This Method gets file
     * @param AbsFileName absolute file name 
     * @return long returns record count of file 
     */
    public boolean setOutputFileRecordCount(String aLogicalFileName,
            String aAsOfDate, long aRecordCount, int runNum) throws TIERSBatchException {
        int runNo = 0;
        try {
            //runNo = getAdjustedMaximumRunNo();
            if (runNo > 0 ){
            runNo = getParallelRunNum();
            runNo--;
            }
            if (isParallelRunProgram()) {
                bfcDAO.lockOutputFiles(getTIERSBatchControllerConnection(),
                        getJobId(), getAsOfDate());
            }
           // System.err.println("LogicalFilename ="+aLogicalFileName);
            bfcDAO.updateFileControlRecordCount(
                    getTIERSBatchControllerConnection(), jobId,
                    aLogicalFileName, aAsOfDate, runNo, aRecordCount,
                    createUpdateUserId);
          //  System.err.println("Record Count TBC "+aRecordCount);
        //    System.err.println("Run Num = "+runNo);
            if (isParallelRunProgram()) {
                bfcDAO.unlockOutputFiles(getTIERSBatchControllerConnection(),
                        getJobId(), getAsOfDate());
            }
            return true;
        } catch (Exception ex) {
            throw new TIERSBatchException(
                    "Error in Updating File Control Record Count "
                            + ex.getMessage(), ex);
        }
    }
    
    /**
     * This method returns a boolean values
     * true if env is production false if test
     * @return boolean returns true or false
     * @throws TIERSBatchException
    */
    
    public boolean isEnvironmentProduction() throws TIERSBatchException {
		boolean isProdEnv = false;
		String env = null;
		env = getTIERSProperties().getProperty("SWSS_ENV");
		if (env == null || !env.equalsIgnoreCase("PROD")) {
			isProdEnv = false;
		} else {
			isProdEnv = true;
		}
		return isProdEnv;
	}
    
    
    /**
     * @param cargo passing values of FwBatchFileControlCargo
     * @return String returns fileName
     * @throws TIERSBatchException
     */
    
    public String getAbsoluteFileName(FwBatchFileControlCargo cargo) throws TIERSBatchException{
    	
    	StringBuffer sBFtpFilePath = new StringBuffer();
    	String aJobId = null;
    	String logicalFilename = null;
    	String inpFolder = null;    	    	
    	sBFtpFilePath = null;
		sBFtpFilePath = new StringBuffer();
		String FileName = null;
		String environment = getTIERSProperties().getProperty(
				BatchConstants.PROPERTY_TAG_ENVIRONMENT);
		String DOUBLE_BACKWARD_SLASH = "\\";
		String FORWARD_SLASH = "/";
		String localDirectory ;
		String absoluteFileName;
		

		aJobId = cargo.getJobId();

		logicalFilename = cargo.getLogicalFileName();

		String tempAsofdate = cargo.getAsOfDt()
				.toString().substring(0, 10);

		String runNumber = "run" + cargo.getRunNum();

		StringTokenizer st = new StringTokenizer(tempAsofdate, "-");

		String year = st.nextToken();

		String month = st.nextToken();

		String date = st.nextToken();

		String asofdate = month + "-" + date + "-" + year;

		String fileType = logicalFilename.substring(logicalFilename
				.length() - 3, logicalFilename.length());

		

		if (fileType.equals(BatchConstants.FILE_TYPE_DATA)) {
			inpFolder = BatchConstants.DIR_NAME_DATA;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_REPORT)) {
			inpFolder = BatchConstants.DIR_NAME_REPORT;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_SORT)) {
			inpFolder = BatchConstants.DIR_NAME_SORT;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_TEMP)) {
			inpFolder = BatchConstants.DIR_NAME_TEMP;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_PRINT)) {
			inpFolder = BatchConstants.DIR_NAME_PRINT;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_SPLIT)) {
			inpFolder = BatchConstants.DIR_NAME_SPLIT;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_MERGE)) {
			inpFolder = BatchConstants.DIR_NAME_MERGE;
		} else if (fileType.equals(BatchConstants.FILE_TYPE_LEGACY)) {
			inpFolder = BatchConstants.DIR_NAME_LEGACY;
		}

		if (TIERSBatchController.operatingSystem
				.equalsIgnoreCase("WINDOWS")) {
			sBFtpFilePath.append(environment);
			sBFtpFilePath.append(DOUBLE_BACKWARD_SLASH);
			sBFtpFilePath.append(aJobId.substring(0, 2).toLowerCase());
			sBFtpFilePath.append(DOUBLE_BACKWARD_SLASH);
			sBFtpFilePath.append(inpFolder);
			sBFtpFilePath.append(DOUBLE_BACKWARD_SLASH);
		} else {
			sBFtpFilePath.append(environment);
			sBFtpFilePath.append(FORWARD_SLASH);
			sBFtpFilePath.append(aJobId.substring(0, 2).toLowerCase());
			sBFtpFilePath.append(FORWARD_SLASH);
			sBFtpFilePath.append(inpFolder);
			sBFtpFilePath.append(FORWARD_SLASH);
		}

		localDirectory = sBFtpFilePath.toString();

		StringBuffer absSbFileName = new StringBuffer();
		absSbFileName.append(localDirectory);
		absSbFileName.append(aJobId);
		absSbFileName.append(".");
		absSbFileName.append(logicalFilename);
		absSbFileName.append("-");
		absSbFileName.append(asofdate);
		absSbFileName.append(".");
		absSbFileName.append(runNumber);
		
		absoluteFileName = absSbFileName.toString();

    	return absoluteFileName;
    }
    
    /**
     * @param cargo passing values of FwBatchFileControlCargo
     * @return String retuns meesage queue Name
     * @throws TIERSBatchException
     */
    public String getMessagingQueueName(String propName){
    	String messagingQueue = null;
    	messagingQueue=  MessagingProperty.getProperty(propName);
    	return messagingQueue;
    }
    
    // BRGUS00266110 - NaredlaS
    /**
     * This method returns the flat Y or N depening upon the batch day 0 entry
     * @param job_id batch job id
     * @return String retstart value Y or N
     */
	private String getBatchRestartFlag(String job_id) {
		
		FwBatchContextCargo params = new FwBatchContextCargo();
		String contextRestart = "N";
		params.setJobId(job_id);
		params.setKeyColumn("RESTART");

		FwBatchContextCargo[] fwBatchContextCargo = null;

		FwBatchContextCollection contextCollection;
		try {
			contextCollection = new FwBatchContextCollection(getConnection());
			contextCollection.setCargo(params);
			fwBatchContextCargo = (FwBatchContextCargo[]) contextCollection
					.select("findByCommitKey");

		} catch (Exception e) {
			throw new FwException(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, e);
		}

		if (fwBatchContextCargo != null && fwBatchContextCargo.length > 0)
			contextRestart = fwBatchContextCargo[0].getJobKeyValue();

		return contextRestart;
	}

    // BRGUS00266110 - NaredlaS	
	/**
	 * This Method returns if a batch job has been aborted and can be restarted
	 * 
	 * @param jobId The identifier for the job
	 * @return boolean returns true or false
	 * @throws ApplicationException
	 */
	public boolean isProgramRestarted(String jobId) throws ApplicationException {

		boolean result = false;

		FwBatchRunControlCargo[] params = { new FwBatchRunControlCargo() };
		java.sql.Timestamp tAsofDate = DataFormatter.strDateToTimestamp(
				getAsOfDate(), "mm/dd/yyyy");
		params[0].setJobId(jobId);
		params[0].setParallelRunNum(getParallelRunNum());
		params[0].setAsOfDt(tAsofDate);

		FwBatchRunControlCollection batchRunControlCollection = new FwBatchRunControlCollection(
				getTIERSBatchControllerConnection());
		FwBatchRunControlCargo[] returnRunControlCargos;
		try {
			returnRunControlCargos = (FwBatchRunControlCargo[]) batchRunControlCollection
					.select("findByAbortStatusforParallelRunNum", params);
		} catch (Exception ex) {
			getLogger()
					.log(FwConstants.LOGGING_CATEGORY_FRAMEWORK,
							ILog.ERROR,
							"Error reading from FW_BATCH_RUN_CONTROL with finder findByAbortStatusforParallelRunNum. Message: "
									+ ex.getMessage(), ex);
			throw new TIERSBatchException(
					"Error reading from FW_BATCH_RUN_CONTROL with finder findByAbortStatusforParallelRunNum. Message: "
							+ ex.getMessage(), ex);
		}
		if (returnRunControlCargos != null
				&& returnRunControlCargos.length > 0
				&& "AB".equalsIgnoreCase(returnRunControlCargos[0]
						.getStatusCd())) {
			result = true;
		}
		return result;
	}

	/**
	 * this method searches for a given search pattern in the header text
	 * 
	 * @param physicalFileName
	 *            batch physical file name
	 * @param pattern
	 *            search pattern
	 * @param numberOfLines
	 *            number of lines that needs to be searched
	 * @return String
	 * @throws TIERSBatchException
	 */
	public String getHeaderText(String physicalFileName, String pattern,
			int numberOfLines) throws TIERSBatchException {

		StringBuffer command = new StringBuffer();
		String HEAD = " head ";
		String output = null;
		String env = getEnv();
		// BRGUS00269696 - file ext changed to ksh
		command.append(env);
		command.append("/fw/script/getTextFromFile.ksh ");
		command.append(physicalFileName);
		command.append(HEAD);
		command.append(pattern);
		command.append(" ");
		command.append(numberOfLines);

		try {
			output = (String) SystemOperator.getInstance()
					.execute(command.toString()).get(0);
		} catch (Exception ex) {
			getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR,
					"Error in tbc.getHeaderText. Message: " + ex.getMessage(),
					ex);
			throw new TIERSBatchException(
					"Error in tbc.getHeaderText. Message: " + ex.getMessage(), ex);
		}
		return output;
	}

	/**
	 * this method searches for a given search pattern in the trailer text
	 * @param physicalFileName batch physical file name 
	 * @param pattern search pattern
	 * @param numberOfLines number of lines that needs to be searched
	 * @return String
	 * @throws TIERSBatchException
	 */
	public String getTrailerText(String physicalFileName, String pattern,
			int numberOfLines) throws TIERSBatchException {

		StringBuffer command = new StringBuffer();
		String TAIL = " tail ";
		String output = null;
		String env = getEnv();
		// BRGUS00269696 - file ext changed to ksh

		command.append(env);
		command.append("/fw/script/getTextFromFile.ksh ");
		command.append(physicalFileName);
		command.append(TAIL);
		command.append(pattern);
		command.append(" ");
		command.append(numberOfLines);

		try {
			output = (String) SystemOperator.getInstance()
					.execute(command.toString()).get(0);
		} catch (Exception ex) {
			getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR,
					"Error in getTrailerText. Message: " + ex.getMessage(),
					ex);
			throw new TIERSBatchException(
					"Error in getTrailerText. Message: " + ex.getMessage(), ex);
		}
		return output;
	}
	
	/**
	 * This method writes the summary for a batch job execution.
	 * 
	 * @param ReadRecCnt
	 * @param ProcessedRecCnt
	 * @param ErrorRecCnt
	 * @throws TIERSBatchException
	 */
	public void insertSummaryRecord(Integer readRecCnt, Integer processedRecCnt, Integer errorRecCnt) throws TIERSBatchException {
		StringBuffer reportLinesBuffer = new StringBuffer();
		reportLinesBuffer.append("Read:").append(readRecCnt);
		reportLinesBuffer.append(" | Processed:").append(processedRecCnt);
		reportLinesBuffer.append(" | Error:").append(errorRecCnt);
		String reportLines[] = { reportLinesBuffer.toString() };
		String columnTypes[] = { BatchConstants.REPORT_TITLE };
		// generate the Summary Report
		batchController.generateReport(reportLines, columnTypes);
	}
	
	/**
	 * This method writes the summary for a batch job execution.
	 * 
	 * @param readRecCnt
	 * @param processedRecCnt
	 * @param unProcessedRecCnt
	 * @param errorRecCnt
	 * @param invalidCnt
	 * @param triggerCnt
	 * @throws TIERSBatchException
	 */
	public void insertSummaryInLtcImpactRecord(Integer readRecCnt, Integer processedRecCnt,Integer unProcessedRecCnt,
			Integer errorRecCnt,Integer invalidCnt,Integer triggerCnt) throws TIERSBatchException {
		StringBuffer reportLinesBuffer = new StringBuffer();
		reportLinesBuffer.append("Read:").append(readRecCnt);
		reportLinesBuffer.append(" | Invalid:").append(invalidCnt);
		reportLinesBuffer.append(" | Processed:").append(processedRecCnt);
		reportLinesBuffer.append(" | triggers:").append(triggerCnt);
		reportLinesBuffer.append(" | Skipped:").append(unProcessedRecCnt);
		reportLinesBuffer.append(" | Error:").append(errorRecCnt);
		String reportLines[] = { reportLinesBuffer.toString() };
		String columnTypes[] = { BatchConstants.REPORT_TITLE };
		// generate the Summary Report
		batchController.generateReport(reportLines, columnTypes);
	}
	
	/**
	 * This method writes the summary for a provider batch job execution.
	 * 
	 * @param readRecCnt
	 * @param processedRecCnt
	 * @param unProcessedRecCnt
	 * @param errorRecCnt
	 * @param delCount
	 * @throws TIERSBatchException
	 */
	public void insertSummaryInLtcProviderRecord(Integer readRecCnt, Integer processedRecCnt,Integer unProcessedRecCnt,
			Integer errorRecCnt,int delCount) throws TIERSBatchException {
		StringBuffer reportLinesBuffer = new StringBuffer();
		reportLinesBuffer.append("Read:").append(readRecCnt);
		reportLinesBuffer.append(" | Processed:").append(processedRecCnt);
		reportLinesBuffer.append(" | Skipped:").append(unProcessedRecCnt);
		reportLinesBuffer.append(" | Error:").append(errorRecCnt);
		reportLinesBuffer.append(" | Deleted:").append(delCount);
		String reportLines[] = { reportLinesBuffer.toString() };
		String columnTypes[] = { BatchConstants.REPORT_TITLE };
		// generate the Summary Report
		batchController.generateReport(reportLines, columnTypes);
	}

	protected ILog getLogger() {
		if (logger == null) {
			logger = (ILog) FwServiceFactory.getInstance().create(ILog.class);
		}
		return logger;
	}
	
	/**
	 * This method logs the number of connections closed into FW_BATCH_SUMMARY.
	 * 
	 * @throws TIERSBatchException
	 */
	public void logConnectionInfo() throws TIERSBatchException {

		int runNumber = this.getMaximumRunNo();
		int connectionPoolSize = 0;

		runNumber++;
		String temp_JobId = null;

		if (isLoadUtility) {
			temp_JobId = jobId.substring(0, 9) + "LDU";
		} else {
			temp_JobId = jobId;
		}

		connectionPoolSize = batchConnManager.getConnectionPoolSize();

		bsc.insertSummaryRecord(getTIERSBatchControllerConnection(),
				temp_JobId, getAsOfDate(), runNumber, ++batchSummaryRecordNum,
				"DB Connections Opened: " + connectionPoolSize + " | Closed: " + batchConnManager.getConnectionCount(),
				createUpdateUserId, programName, BatchConstants.REPORT_BODY,
				getParallelRunNum());

	}
	
    /**
     * This method returns the threshold value
     * @param jobId
     * @return Long thresholdValue
     */
	private String getThresholdValue(String jobId){
		FwBatchContextCargo params = new FwBatchContextCargo();
		params.setJobId(jobId);
		FwBatchContextCargo[] fwBatchContextCargo = null;

		FwBatchContextCollection contextCollection;
		try {
			contextCollection = new FwBatchContextCollection(getConnection());
			contextCollection.setCargo(params);
			fwBatchContextCargo = (FwBatchContextCargo[]) contextCollection.select("findThresholdByJobId");
			if(fwBatchContextCargo.length>0){
				return fwBatchContextCargo[0].getJobKeyValue();
			}
		} catch (Exception e) {
			throw new FwException(e.getMessage(), e);
		}
		
		return FwConstants.EMPTY_STRING;
	}
	
	private void checkFromPostProcess(){
		if(!fromPostProcess){
			for(StackTraceElement e: Thread.currentThread().getStackTrace()){
				if(e.getMethodName().equals("postProcess")){
					fromPostProcess = true;
					break;
				}
			}
		}
	}
	
	private Boolean isThresholdDataScanActivated(){
		return "true".equalsIgnoreCase(System.getProperty(FwConstants.THRESHOLD_DATA_SCAN));
	}

	private void checkStatusException(int statusCode, String exceptionCode) throws Exception{
		if(statusCode == BatchConstants.EXIT_FAILURE 
			|| BatchConstants.FATAL.equals(exceptionCode) 
			|| FWUtils.isFatalExceptionOccurred()
			|| (isThresholdDataScanActivated() && !BatchConstants.INFO.equals(exceptionCode))
		){
			
			String abortMessage = "";
			if(statusCode == BatchConstants.EXIT_FAILURE){
				TIERSBatchController.stop = true;
				getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, "Threshold reached.");
				abortMessage = "Threshold reached. Exception count: "+batchExcController.numberOfExceptions;
			}
			if(BatchConstants.FATAL.equals(exceptionCode)){
				TIERSBatchController.stop = true;
				getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, "Fatal exception. Exiting the batch. ");
			}
			if(FWUtils.isFatalExceptionOccurred()){
				TIERSBatchController.stop = true;
				getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, "Fatal exception. Framework or TIERSRunTimeException");
				abortMessage = "Fatal exception. Framework or TIERSRunTimeException";
			}
			if(isThresholdDataScanActivated()){
				getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, "Threshold Data Scan is activated.");
				if(StringUtils.isEmpty(abortMessage)) abortMessage = "Threshold Data Scan is activated.";
			}
			
			if(!fatalExceptionSaved && !BatchConstants.FATAL.equals(exceptionCode)){
				try {
					fatalExceptionSaved = true;
					writeExceptionRecord(BatchConstants.FATAL, "Batch Aborted", abortMessage, false);
				} catch (TIERSBatchException e) {
					throw new FwException(e);
				}
			}
			String multithread = System.getProperty(FwConstants.MULTITHREAD);
			if(!"true".equals(multithread)){
				checkFromPostProcess();
				if(!fromPostProcess && !redirectedPostProcess && !postProcessCalled){
					redirectedPostProcess = true;
					getConnection().rollback();
					postProcessAbortAndExit();
				}
			}
		}
	}
	
	private void postProcessAbortAndExit(){
		try {
			if(getCallerRef() instanceof AbstractBatch){
				getLogger().log(FwConstants.LOGGING_DEFAULT_CATEGORY, ILog.INFO, "Redirected to PostProcess");
				((AbstractBatch)getCallerRef()).callPostProcessMethod();
			}
		} catch (ApplicationException e1) {
			// PMD_Override - R6 - The functionality here is working as expected, we should not throw the exception and the next step is to abort the job.
        	PMDRules.markApprovedCatchBlock("R6");
			getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, "Error while trying to execute postProcess() after redirection to exit." +e1.getMessage(), e1);
		}
		try {
			// PMD_Override - R7 - The functionality here is working as expected, we should abort the job in postPrcoessAbortAndExit method..
        	PMDRules.markApprovedStatement("R7");
			stop(BatchConstants.ABORT);
		} catch (ApplicationException e1) {
			// PMD_Override - R6 - The functionality here is working as expected, we should not throw the exception and the next step is to exit the job.
        	PMDRules.markApprovedCatchBlock("R6");
			getLogger().log(FwConstants.LOGGING_CATEGORY_FRAMEWORK, ILog.ERROR, "Error while trying to execute abort() after redirection to exit." +e1.getMessage(), e1);
		}
		getLogger().log(FwConstants.LOGGING_DEFAULT_CATEGORY, ILog.INFO, "Exit because of the threshold or fatal exception is logged.");
		// PMD_Override - R7 - The functionality here is working as expected, we should exit the job in postPrcoessAbortAndExit method..
    	PMDRules.markApprovedStatement("R7");
		System.exit(BatchConstants.EXIT_FAILURE);
	}


	public String getThresholdValue() {
		return thresholdValue;
	}
	
	/**
	 * This method grabs the Okta properties configured for the batch job.
	 */
	private void getOktaProperties() {	
		this.oktaAuthentication = "true".equals(batchProperty.getProperty(FwConstants.OKTA_AUTHENTICATION.toString()));
		this.employeeGroupId = batchProperty.getProperty(FwConstants.EMPLOYEE_GROUP_ID.toString());
		this.externalProviderGroupId = batchProperty.getProperty(FwConstants.EXTERNAL_PROVIDER_GROUP_ID.toString());
	}

	/**
	 * Returns if oktaAuthentication is enabled or not.
	 * 
	 * @return oktaAuthentication
	 */
	public boolean isOktaAuthentication() {
		return oktaAuthentication;
	}

	/**
	 * Returns the ID of the Okta Group for Employees.
	 *  
	 * @return employeeGroupId
	 */
	public String getEmployeeGroupId() {
		return employeeGroupId;
	}

	/**
	 * Returns the ID of the Okta Group for External Providers.
	 *  
	 * @return employeeGroupId
	 */
	public String getExternalProviderGroupId() {
		return externalProviderGroupId;
	}
	
	public void setParallelRunIdSEBT(String aparallelRunId) {
		 parallelRunProgram = BatchConstants.NOTAPPLICABLE;
    }

}